{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNtHCC3nFFzKx00CwFINELx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fragmede/wc-gpu/blob/main/wc_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "from numba import cuda"
      ],
      "metadata": {
        "id": "sp259KoLUExd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the CUDA kernel\n",
        "@cuda.jit\n",
        "def count_lwc_kernel(data, line_count, word_count, char_count):\n",
        "    idx = cuda.grid(1)\n",
        "    if idx < data.size:\n",
        "        # Count characters\n",
        "        cuda.atomic.add(char_count, 0, 1)\n",
        "        # Count lines\n",
        "        if data[idx] == 10:  # ASCII for newline\n",
        "            cuda.atomic.add(line_count, 0, 1)\n",
        "        # Count words\n",
        "        if idx < data.size - 1:\n",
        "            if data[idx] not in [32, 9, 10] and data[idx + 1] in [32, 9, 10]:\n",
        "                cuda.atomic.add(word_count, 0, 1)\n",
        "        if idx == data.size - 1 and data[idx] not in [32, 9, 10]:\n",
        "            cuda.atomic.add(word_count, 0, 1)\n",
        "\n",
        "# Step 2: Convert string to NumPy array\n",
        "def load_data_from_string(input_string):\n",
        "    # Encode the string as UTF-8\n",
        "    data = np.frombuffer(input_string.encode('utf-8'), dtype=np.uint8)\n",
        "    return data\n",
        "\n",
        "# Step 3: Allocate memory on GPU and copy data\n",
        "def count_lwc(data):\n",
        "    line_count = np.zeros(1, dtype=np.int32)\n",
        "    word_count = np.zeros(1, dtype=np.int32)\n",
        "    char_count = np.zeros(1, dtype=np.int32)\n",
        "\n",
        "    d_data = cuda.to_device(data)\n",
        "    d_line_count = cuda.to_device(line_count)\n",
        "    d_word_count = cuda.to_device(word_count)\n",
        "    d_char_count = cuda.to_device(char_count)\n",
        "\n",
        "    # Step 4: Define the grid and block dimensions\n",
        "    threads_per_block = 256\n",
        "    blocks_per_grid = (data.size + (threads_per_block - 1)) // threads_per_block\n",
        "\n",
        "    # Launch the kernel\n",
        "    count_lwc_kernel[blocks_per_grid, threads_per_block](d_data, d_line_count, d_word_count, d_char_count)\n",
        "\n",
        "    # Step 5: Copy the results back to host\n",
        "    line_count = d_line_count.copy_to_host()\n",
        "    word_count = d_word_count.copy_to_host()\n",
        "    char_count = d_char_count.copy_to_host()\n",
        "\n",
        "    return line_count[0]+1, word_count[0], char_count[0]+1\n"
      ],
      "metadata": {
        "id": "UNBzvuUnUI3b"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_string(string, spec):\n",
        "    data = load_data_from_string(string)\n",
        "    calculated_counts = count_lwc(data)\n",
        "    if calculated_counts != spec:\n",
        "        print(\"counted\", string, \"wrong\", calculated_counts, spec)"
      ],
      "metadata": {
        "id": "pScYiZYGWfCx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_string = \"     word1      word2     word3       \"\n",
        "\n",
        "data = load_data_from_string(input_string)\n",
        "counts = count_lwc(data)\n",
        "print(f\"Number of words: {counts}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqFPnbIJVQ_F",
        "outputId": "5bbfbb38-b070-4261-b134-d95feac48b0c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words: (0, 3, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_string('now with 23 a number',                   (1, 5, 21))\n",
        "test_string('now with 23.17',                         (1, 3, 15))\n",
        "test_string(\"emoji ðŸ˜ðŸ˜ do not count\",                (1, 5, 28))\n",
        "test_string(\"possessive's are one word\",              (1, 4, 26))\n",
        "test_string('some \"quoted text\" does not impact',     (1, 6, 35))\n",
        "test_string(\"also 'single quotes' are ok\",            (1, 5, 28))\n",
        "test_string(\"don't do contractions\",                  (1, 3, 22))\n",
        "test_string('hyphenated words-are considered whole',  (1, 4, 38))\n",
        "test_string('underbars are_too just one',             (1, 4, 27))\n",
        "test_string('n-dash ranges 1â€“3 are NOT',              (1, 5, 28))\n",
        "test_string('m-dash connectedâ€”bits also are not',     (1, 5, 37))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiEHex4yWpLG",
        "outputId": "6b626a37-057e-4799-e3dc-dfcf27a97b09"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load data from file\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "    return data"
      ],
      "metadata": {
        "id": "YAA_M2RII0IJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_file(filename):\n",
        "    data = load_data(filename)\n",
        "    counts = count_lwc(data)\n",
        "    #print(f\"Number of words: {word_count}\")"
      ],
      "metadata": {
        "id": "teaPCDg7I4Sy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [ 'ascii.txt',\n",
        "          'pocorgtfo18.pdf',\n",
        "          'space.txt',\n",
        "          'utf8.txt',\n",
        "          'word.txt',\n",
        "        ]\n",
        "for file in files:\n",
        "    duration = timeit.timeit(lambda: test_file(file), number=1)\n",
        "    print(f\"{file}: {duration} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caFyd7YXIQGN",
        "outputId": "3b6c8b9d-9850-4a07-d2b2-7935ac73dc27"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ascii.txt: 0.1808300140000938 seconds\n",
            "pocorgtfo18.pdf: 0.17899091699973724 seconds\n",
            "space.txt: 0.18513659300015206 seconds\n",
            "utf8.txt: 0.17958779099990352 seconds\n",
            "word.txt: 0.17560361200003172 seconds\n"
          ]
        }
      ]
    }
  ]
}